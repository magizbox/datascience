http://www.datascienceontology.com/

![](http://www.nerdgraph.com/wp-content/uploads/How-to-become-a-data-scientist-620x2837.jpg)

# DS: 101

# Data Science: Questions and Answers

<h4>What is Precision and recall? <sup id="fnref-922-1"><a href="#fn-922-1" rel="footnote">1</a></sup></h4>

<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/350px-Precisionrecall.svg.png" alt="" />

<h4>What are 'Overfitting' and 'Underfitting'? <sup id="fnref-922-2"><a href="#fn-922-2" rel="footnote">2</a></sup> <img class="alignnone" src="http://pingax.com/wp-content/uploads/2014/05/underfitting-overfitting.png" alt="" width="555" height="140" /></h4>

<h4>What are popular algorithms? <sup id="fnref2:922-2"><a href="#fn-922-2" rel="footnote">2</a></sup></h4>

<ul>
<li>Decision Trees</li>
<li>Neural Networks (back propagation)</li>
<li>Probabilistic networks</li>
<li>Nearest Neighbor</li>
<li>Support vector machines</li>
</ul>

<h4>Describe a "Rolls Royce" solution that you could implement in 3 months, 3 weeks and 3 days.</h4>

[!TODO]

<h2>Machine Learning Problems <sup id="fnref-922-3"><a href="#fn-922-3" rel="footnote">3</a></sup></h2>

[!TODO]

<h4>How would you generate related searches on Bing? <sup id="fnref2:922-3"><a href="#fn-922-3" rel="footnote">3</a></sup></h4>

[!TODO]

<h4>How would you approach the Netflix Prize? <sup id="fnref3:922-3"><a href="#fn-922-3" rel="footnote">3</a></sup></h4>

[!TODO]

<h4>How would you suggest followers on Twitter? <sup id="fnref4:922-3"><a href="#fn-922-3" rel="footnote">3</a></sup></h4>

[!TODO]

<div class="footnotes">
<hr />
<ol>

<li id="fn-922-1">
<a href="https://en.wikipedia.org/wiki/Precision_and_recall" target="_blank">https://en.wikipedia.org/wiki/Precision_and_recall</a>&#160;<a href="#fnref-922-1" rev="footnote">&#8617;</a>
</li>

<li id="fn-922-2">
<a href="http://career.guru99.com/top-50-interview-questions-on-machine-learning/" target="_blank">http://career.guru99.com/top-50-interview-questions-on-machine-learning/</a>&#160;<a href="#fnref-922-2" rev="footnote">&#8617;</a> <a href="922-2" rev="footnote">&#8617;</a>
</li>

<li id="fn-922-3">
<a href="http://www.quora.com/What-are-the-best-interview-questions-to-evaluate-a-machine-learning-researcher" target="_blank">http://www.quora.com/What-are-the-best-interview-questions-to-evaluate-a-machine-learning-researcher</a>&#160;<a href="#fnref-922-3" rev="footnote">&#8617;</a> <a href="922-3" rev="footnote">&#8617;</a> <a href="922-3" rev="footnote">&#8617;</a> <a href="922-3" rev="footnote">&#8617;</a>
</li>

</ol>
</div>

# DS: Python Data Mining Folder Structure

```
code/
├── data/
└── script.py
```

# Competition

# Kaggle

<strong>The reasons why you should take a competition</strong>

According to <a href="http://www.kdnuggets.com/2015/03/10-steps-success-kaggle-data-science-competitions.html" target="_blank">Yanir Seroussi</a>, if you’re a data scientist (or want to become one), participating in competitions is a great way of honing your skills, building reputation, and potentially winning some cash.

<strong>Introduction to <a href="https://www.kaggle.com/" target="_blank">Kaggle</a></strong>

<p class="intro">Kaggle is the world's largest community of data scientists. They compete with each other to solve complex data science problems, and the top competitors are invited to work on the most interesting and sensitive business problems from some of the world’s biggest companies through Masters competitions.</p>

<p class="intro">Kaggle provides cutting-edge data science results to companies of all sizes. We have a proven track-record of solving real-world problems across a diverse array of industries including life sciences, financial services, energy, information technology, and retail.</p>

<strong>Profiling top Kagglers</strong>

<ul>
    <li><a href="http://blog.kaggle.com/2015/05/07/profiling-top-kagglers-kazanovacurrently-2-in-the-world/" target="_blank">Profiling Top Kagglers: KazAnova Currently #2 in the World</a></li>
    <li><a href="http://blog.kaggle.com/2015/06/22/profiling-top-kagglers-owen-zhang-currently-1-in-the-world/" target="_blank">Profiling Top Kagglers: Owen Zhang, Currently #1 in the World</a></li>
</ul>

<strong>How to compete</strong> <sup id="fnref-15-1"><a href="#fn-15-1" rel="footnote">1</a></sup>

<img class="alignnone" src="https://lh3.googleusercontent.com/rTCsoldaVmbWKP5dOpmQOuDyOcNa2IhE64WIIG1iYm-2=w720-h637-no" alt="" width="720" height="637" />

<ol>
    <li>Read the manual</li>
    <li>Understand the performance measure</li>
    <li>Know your data</li>
    <li>Understand what you want to achieve before worrying about the how</li>
    <li>Set up a local validation environment</li>
    <li>Monitor the forum</li>
    <li>Do your research</li>
    <li>Apply the basics rigorously</li>
    <li>Ensemble all the things</li>
    <li>Win</li>
</ol>

<strong>Tools</strong>

<em>Exploring Data</em>

<ul>
    <li><a href="http://sqlitestudio.pl/" target="_blank">SQLiteStudio</a></li>
</ul>

<em>IDE</em>

<ul>
    <li><a href="https://datayo.wordpress.com/2015/06/23/pycharm-python-ide-for-data-scientist/" target="_blank">Pycharm for Python</a></li>
    <li><a href="https://datayo.wordpress.com/2015/05/09/r-ide/" target="_blank">RStudio for R</a></li>
</ul>

<em>Machine learning libraries</em>

Python: scikit-learn, XGBoost, Vowpal Wabbit, cuda-convnet2

R <sup id="fnref-15-2"><a href="#fn-15-2" rel="footnote">2</a></sup> : gbm, randomForest, e1071, glmnet, tau, Matrix, SOAR, forEach, doMC, data.table

### Articles

* [What do top Kaggle competitors focus on?](https://www.quora.com/What-do-top-Kaggle-competitors-focus-on)

<div class="footnotes">
<hr />
<ol>

<li id="fn-15-1">
Yanir Seroussi, 2015. <em>10 Steps to Success in Kaggle Data Science Competitions</em>. [ONLINE] Available at: <a href="http://www.kdnuggets.com/2015/03/10-steps-success-kaggle-data-science-competitions.html" target="_blank">http://www.kdnuggets.com/2015/03/10-steps-success-kaggle-data-science-competitions.html</a>. [Accessed 10 March 2015].&#160;<a href="#fnref-15-1" rev="footnote">&#8617;</a>
</li>

<li id="fn-15-2">
DataRobot, 2015. <em>10 R Packages to Win Kaggle Competitions</em>. [ONLINE] Available at <a href="http://www.slideshare.net/DataRobot/final-10-r-xc-36610234" target="_blank">http://www.slideshare.net/DataRobot/final-10-r-xc-36610234</a> [Accessed 03 July 2014].&#160;<a href="#fnref-15-2" rev="footnote">&#8617;</a>
</li>

</ol>
</div>

# Tools

# Third Party APIs

Original post: [http://www.kdnuggets.com/2015/11/machine-learning-apis-data-science.html/2](http://www.kdnuggets.com/2015/11/machine-learning-apis-data-science.html/2)

Keep update your knowledge with many conferences, groups and social networks about machine learning and data mining

# Conferences, Journals, Groups, Social Networks and People
<h3>Conferences</h3>

<a href="http://icml.cc/" target="_blank">ICML - Internal Conference on Machine Learning</a>

![](http://hci-kdd.org/wordpress/wp-content/uploads/2014/11/International-Conference-Machine-Learning-2016.jpg)

The International Conference on Machine Learning (ICML) is the leading international academic conference in machine learning, attracting annually about 500 participants from all over the world. It is supported by the International Machine Learning Society (IMLS). The conference attracts leading innovations in the field of machine learning.

<a href="https://nips.cc/" target="_blank">NIPS - Annual Conference on Neural Information Processing </a>

The Conference and Workshop on Neural Information Processing Systems (NIPS) is a machine learning and computational neuroscience conference held every December. The conference is a single track meeting that includes invited talks as well as oral and poster presentations of refereed papers, followed by parallel-track workshops that up to 2013 were held at ski resorts. According to Microsoft Academic Search, NIPS is the top conference on machine learning.

<a href="http://www.dlworkshop.org/" target="_blank">NIPS Deep Learning Workshop </a>

<small>2015, <a href="http://www.dlworkshop.org/" target="_blank">2014</a>, <a href="https://sites.google.com/site/deeplearningworkshopnips2013/" target="_blank">2013</a>, <a href="https://sites.google.com/site/deeplearningnips2012/" target="_blank">2012</a>, <a href="https://deeplearningworkshopnips2011.wordpress.com/" target="_blank">2011</a>, <a href="https://deeplearningworkshopnips2010.wordpress.com/" target="_blank">2010</a></small>

The Deep Learning and Representation Learning Workshop will be held in conjunction with Neural Information Processing Systems (NIPS)

Deep Learning algorithms attempt to discover good representations, at multiple levels of abstraction. There has been rapid progress in this area in recent years, both in terms of algorithms and in terms of applications, but many challenges remain. The workshop aims at bringing together researchers in that field and discussing these challenges, brainstorming about new solutions.

<a href="http://www.sigkdd.org/" target="_blank">ACM SIGKDD</a>

<small><a href="http://www.kdd.org/kdd2015/" target="_blank">2015</a>, <a href="http://www.kdd.org/kdd2014/" target="_blank">2014</a>, <a href="http://www.kdd.org/kdd2013/" target="_blank">2013</a></small>

KDD provides the premier forum for advancement and adoption of the "science" of knowledge discovery and data mining. KDD encourages:

<ul>
    <li>Research in KDD (through annual research conferences, newsletter and other related activities)
Adoption of "standards" in the market in terms of terminology, evaluation, methodology
Interdisciplinary education among KDD researchers, practitioners, and users
KDD activities include the annual Conference on Knowledge Discovery and Data Mining and the SIGKDD Explorations Newsletter.</li>
</ul>

<h3>Journals</h3>

<a href="http://jmlr.csail.mit.edu/" target="_blank">JMLR - Journal of Machine Learning Research</a>

The Journal of Machine Learning Research (JMLR) provides an international forum for the electronic and paper publication of high-quality scholarly articles in all areas of machine learning. All published papers are freely available online.

<a href="http://www.jair.org/" target="_blank">JAIR - Journal of Artificial Intelligence Research</a>

JAIR(ISSN 1076 - 9757) covers all areas of artificial intelligence (AI), publishing refereed research articles, survey articles, and technical notes. Established in 1993 as one of the first electronic scientific journals, JAIR is indexed by INSPEC, Science Citation Index, and MathSciNet. JAIR reviews papers within approximately three months of submission and publishes accepted articles on the internet immediately upon receiving the final versions. JAIR articles are published for free distribution on the internet by the AI Access Foundation, and for purchase in bound volumes by AAAI Press.

<h3>Groups and Social Networks</h3>

You can join many peer groups - see <a href="http://www.kdnuggets.com/2013/04/top-30-linkedin-groups-analytics-big-data-data-mining-data-science.html" target="_blank">Top 30 LinkedIn Groups for Analytics, Big Data, Data Mining, and Data Science</a>.

<a href="http://www.analyticbridge.com/" target="_blank">AnalyticBridge </a>is an active community for Analytics and Data Science.

You can attend some of the many <a href="http://www.kdnuggets.com/meetings/index.html" target="_blank">Meetings and Conferences on Analytics, Big Data, Data Mining, Data Science, &amp; Knowledge Discovery</a>.

<h3>People</h3>

<a href="https://scholar.google.com/citations?hl=en&amp;user=Q_kKkIUAAAAJ&amp;view_op=list_works" target="_blank">Jure Leskovec</a>: <small>#SocialNetworkAnalysis</small>

<a href="https://scholar.google.com/citations?hl=en&amp;user=JgDKULMAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" target="_blank">Andrew Ng</a>: <small>#DeepLearning</small>

<a href="https://scholar.google.com/citations?user=8OYE6iEAAAAJ" target="_blank">David Blei</a>: <small>#TopicModel</small>

<a href="http://people.csail.mit.edu/matei/" target="_blank">Matei Zaharia</a>: <small>#apachespark , #2013, </small>creator of apache spark, (interview <a href="http://www.kdnuggets.com/2015/05/interview-matei-zaharia-creator-apache-spark.html" target="_blank">#1</a>)

<h4>References</h4>

<ul>
    <li>quora.com, <a href="http://www.quora.com/What-are-the-best-conferences-and-journals-about-machine-learning" target="_blank">What are the best conferences and journals about machine learning?</a></li>
    <li>kdnuggets.com, <a href="http://www.kdnuggets.com/2013/10/7-steps-learning-data-mining-data-science.html" target="_blank">7 Steps for Learning Data Mining and Data Science</a></li>
    <li>kdnuggets.com, <a href="http://www.kdnuggets.com/2013/10/7-steps-learning-data-mining-data-science.html" target="_blank">7 Steps for Learning Data Mining and Data Science</a></li>
</ul>

# DS: Cultures

> What are machine learning cultures? Who are invent and follow what culture?

Inspired from two interesting papers,

* [Leo Breiman, 2001, *Statistical Modeling: The Two Cultures (with comments and a rejoinder by the author)*](http://projecteuclid.org/download/pdf_1/euclid.ss/1009213726)
* [Jason Eisner, 2015, *The Three Cultures of Machine Learning*](https://www.cs.jhu.edu/~jason/tutorials/ml-simplex.html)

Frequentist

Bayesian

Algorithmic Modeling, Deep Learning

# DS: Courses

[Data Science Courses](http://magizbox.com/pages/ds-course/)
